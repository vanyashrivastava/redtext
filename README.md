# 🔴 RedText: Real-Time Coercion Detection Bot

April is Sexual Assault Awareness Month — and with 36.4% of young adults reporting digital sexual coercion, **RedText** is a small step toward protecting people where they communicate most: their group chats.

🚨 **RedText is an AI-powered GroupMe bot that detects harmful, coercive, or manipulative messages and responds in real time with supportive feedback and actions.**

---

## 💡 What It Does

- ✅ Monitors messages in a GroupMe group chat via a bot
- 🧠 Uses **Claude 3.5 Sonnet** (Anthropic) to detect:
  - Guilt-tripping
  - Threats
  - Emotional manipulation
  - Sexual coercion
- 💬 Sends short, warm, emoji-friendly responses when something is flagged
- 🛡 Offers an empowering next step the recipient can take

> Example response:
> ```
> 🚨 That message feels like emotional pressure 😞
> You deserve to set boundaries — protect your space 🛡️❤️
> ```

---

## 🛠 How to Set Up

### 1. 🍃 Clone the Repo
```bash
git clone https://github.com/your-username/redtext-bot.git
cd redtext-bot

💡 Built by Vanya Shrivastava to empower digital safety during Sexual Assault Awareness Month.
🤖 AI safety logic powered by Claude and implemented with guidance from ChatGPT.

