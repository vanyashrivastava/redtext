# ğŸ”´ RedText: Real-Time Coercion Detection Bot

April is Sexual Assault Awareness Month â€” and with 36.4% of young adults reporting digital sexual coercion, **RedText** is a small step toward protecting people where they communicate most: their group chats.

ğŸš¨ **RedText is an AI-powered GroupMe bot that detects harmful, coercive, or manipulative messages and responds in real time with supportive feedback and actions.**

---

## ğŸ’¡ What It Does

- âœ… Monitors messages in a GroupMe group chat via a bot
- ğŸ§  Uses **Claude 3.5 Sonnet** (Anthropic) to detect:
  - Guilt-tripping
  - Threats
  - Emotional manipulation
  - Sexual coercion
- ğŸ’¬ Sends short, warm, emoji-friendly responses when something is flagged
- ğŸ›¡ Offers an empowering next step the recipient can take

> Example response:
> ```
> ğŸš¨ That message feels like emotional pressure ğŸ˜
> You deserve to set boundaries â€” protect your space ğŸ›¡ï¸â¤ï¸
> ```

---

## ğŸ›  How to Set Up

### 1. ğŸƒ Clone the Repo
```bash
git clone https://github.com/your-username/redtext-bot.git
cd redtext-bot

ğŸ’¡ Built by Vanya Shrivastava to empower digital safety during Sexual Assault Awareness Month.
ğŸ¤– AI safety logic powered by Claude and implemented with guidance from ChatGPT.

